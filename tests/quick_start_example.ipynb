{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXrVZkDbB_VA"
   },
   "source": [
    "# **Scenario 3 : Data Generation from a Probability Distribution**\n",
    "\n",
    "As before, we train ANNs or define our own functions to calculate each variable in the DAG. However, instead of a Monte Carlo (agent based) approach, we use Causal Jazz to build a discretised probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqUP4885NJU7"
   },
   "source": [
    "\n",
    "Import the usual suspects and the pmf module from causaljazz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZU_Xl7q3NlvD",
    "outputId": "d583b2f1-939c-47ec-d679-edcb8af551e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.1 (SDL 2.28.2, Python 3.11.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "from causaljazz.visualiser import Visualiser\n",
    "from causaljazz.inference import TEDAG_FUNCTION\n",
    "from causaljazz.inference import TEDAG\n",
    "import causaljazz.data as data\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxsmXKkknvd-"
   },
   "source": [
    "# **Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jJ48ZMAMnx2i"
   },
   "outputs": [],
   "source": [
    "# Return the approximate discretised probability mass function for a normal distribution with x_mean and x_sd. The discretisation goes from x_min to x_max with res bins.\n",
    "def generateGaussianNoisePmf(x_min, x_max, x_mean, x_sd, res):\n",
    "    x_space = np.linspace(x_min, x_max, res)\n",
    "    x_dist = [a * ((x_max-x_min)/res) for a in norm.pdf(x_space, x_mean, x_sd)]\n",
    "    x_pmf = [a / sum(x_dist) for a in x_dist]\n",
    "    return x_pmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGcdzh4gyKMp"
   },
   "source": [
    "Load the original data into an ND-array structure.\n",
    "The original data is made up of up to 25 sets of 1000 data points. Setting number_of_experiments higher improves the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7ARJWnA8yP9v"
   },
   "outputs": [],
   "source": [
    "csv_names = ['X1', 'X2', 'LC', 'X3', 'SF']\n",
    "\n",
    "# Load the data into an array\n",
    "ground = [] # The ground truth array\n",
    "number_of_experiments = 25\n",
    "with open('ground.csv') as csvfile:\n",
    "    ground_reader = csv.DictReader(csvfile)\n",
    "    for row in ground_reader:\n",
    "        if int(row['Sim']) > number_of_experiments:\n",
    "            break\n",
    "        d = [float(a) for a in [row[k] for k in csv_names]]\n",
    "        ground += [d]\n",
    "\n",
    "# Normalise it otherwise training doesn't work!\n",
    "max_vals = np.max(ground, axis=0)\n",
    "min_vals = np.min(ground, axis=0)\n",
    "ground = ((np.array(ground)-min_vals)/(max_vals-min_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHCUCAta4Erb"
   },
   "source": [
    "Set grid resolution variables and flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TKWxUl3n4Ici"
   },
   "outputs": [],
   "source": [
    "generate_models = True\n",
    "\n",
    "input_res = 10\n",
    "output_res = 30\n",
    "output_buffer = 5\n",
    "total_output_size = 2*(output_res+output_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKAhI5F5-Dft"
   },
   "source": [
    "# **Latent Function C**\n",
    "\n",
    "Before learning the ANN functions, let's design our function for C.<br>\n",
    "\n",
    "*func_c* takes two inputs, X<sub>1</sub> and X<sub>2</sub>, and returns a distribution across two values, 0 and 1.\n",
    "\n",
    "To achieve the expected path coefficients, we first define the expected value of a non-dichotomised (non-binary) C based on X<sub>1</sub> and X<sub>2</sub>.\n",
    "<br><br>\n",
    "E[C] <- 0.3X<sub>1</sub> + 0.3X<sub>2</sub>\n",
    "<br><br>\n",
    "Next, we must define the variance of C for each value of X<sub>1</sub> and X<sub>2</sub>. For simplicity we will assume that the variance is normally distributed around the expected value with a standard deviation of 1. The conditional distributions could be dependent on the inputs and considerably more complicated than a normal distribution. Note that any skew or bias in the distribution will affect the resulting covariance.<br><br>\n",
    "If the latent variable is not to be processed further (for example dichotomised), the function is simple and can return a normal distribution around the expected value. However, this imparts no new information from the latent variable beyond some additional variance - which may be all that is required (enigmatic variation). In this case, though, we also wish to capture a 30/70 split between high and low risk groups. <br><br>\n",
    "To get a distribution across two values, 1 and 0, we need to dichotamise the joint distribution so that 30% falls into the high-risk group (C=1). This step has to be performed on the full joint distribution of X<sub>1</sub>, X<sub>2</sub>, and C so that lower values of X<sub>1</sub> and X<sub>2</sub> are more likely to appear in the low-risk group.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Kpi4STItYu1F"
   },
   "outputs": [],
   "source": [
    "def func_c_exp(y):\n",
    "  x1 = np.array(y)[:,0]\n",
    "  x2 = np.array(y)[:,1]\n",
    "\n",
    "  out = np.reshape((0.3*x1 + 0.3*x2), (np.array(y).shape[0],1))\n",
    "  print(out.shape)\n",
    "  return out\n",
    "\n",
    "def func_c_noise(y):\n",
    "  x1 = np.array(y)[:,0]\n",
    "  x2 = np.array(y)[:,1]\n",
    "\n",
    "  out = np.array([generateGaussianNoisePmf(-0.5, 0.5, 0, 0.1, total_output_size) for a in range(np.array(y).shape[0])]).T\n",
    "  print(out.shape)\n",
    "  return out\n",
    "\n",
    "def func_c_sampled(y):\n",
    "  x1 = y[0]\n",
    "  x2 = y[1]\n",
    "\n",
    "  exp_c = 0.3*x1 + 0.3*x2\n",
    "  cont_c = np.random.normal(loc=exp_c, scale=0.1)\n",
    "  return cont_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQlWFXT61M0R"
   },
   "source": [
    "Learn the functions for X<sub>2</sub>, X<sub>3</sub>, and S. In this example dataset, X<sub>1</sub> is normally distributed around 0.0 with a standard deviation of 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1oo3BfJv1q3j",
    "outputId": "7383f5dd-446d-4a72-cdce-31a3522e6fad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0634 - val_loss: 0.0133\n",
      "Epoch 2/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - val_loss: 0.0132\n",
      "Epoch 3/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - val_loss: 0.0131\n",
      "Epoch 4/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - val_loss: 0.0133\n",
      "Epoch 5/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - val_loss: 0.0133\n",
      "Epoch 6/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - val_loss: 0.0132\n",
      "Epoch 7/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - val_loss: 0.0132\n",
      "Epoch 8/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - val_loss: 0.0133\n",
      "Epoch 9/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 10/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 11/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - val_loss: 0.0129\n",
      "Epoch 12/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - val_loss: 0.0131\n",
      "Epoch 13/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 14/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - val_loss: 0.0130\n",
      "Epoch 15/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - val_loss: 0.0134\n",
      "Epoch 16/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - val_loss: 0.0129\n",
      "Epoch 17/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - val_loss: 0.0130\n",
      "Epoch 18/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 19/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 20/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 21/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 22/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 23/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0127 - val_loss: 0.0131\n",
      "[[0.19415202]\n",
      " [0.30543361]\n",
      " [0.17257946]\n",
      " ...\n",
      " [0.67119842]\n",
      " [0.56129794]\n",
      " [0.825536  ]]\n",
      "Epoch 1/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0957 - val_loss: 2.5979e-04\n",
      "Epoch 2/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0980e-04 - val_loss: 1.2625e-04\n",
      "Epoch 3/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1318e-04 - val_loss: 8.4587e-05\n",
      "Epoch 4/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.2264e-05 - val_loss: 7.6291e-05\n",
      "Epoch 5/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.7776e-05 - val_loss: 7.0761e-05\n",
      "Epoch 6/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8921e-05 - val_loss: 6.4447e-05\n",
      "Epoch 7/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.4243e-05 - val_loss: 5.4575e-05\n",
      "Epoch 8/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.7489e-05 - val_loss: 2.7845e-05\n",
      "Epoch 9/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3499e-05 - val_loss: 1.2258e-05\n",
      "Epoch 10/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1782e-05 - val_loss: 7.4140e-06\n",
      "Epoch 11/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.3472e-06 - val_loss: 6.0075e-06\n",
      "Epoch 12/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.3708e-06 - val_loss: 5.3608e-06\n",
      "Epoch 13/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.8524e-06 - val_loss: 4.9907e-06\n",
      "Epoch 14/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0236e-06 - val_loss: 4.7452e-06\n",
      "Epoch 15/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.1678e-06 - val_loss: 4.5833e-06\n",
      "Epoch 16/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8719e-06 - val_loss: 4.4760e-06\n",
      "Epoch 17/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4042e-06 - val_loss: 4.3703e-06\n",
      "Epoch 18/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.0350e-06 - val_loss: 4.3218e-06\n",
      "Epoch 19/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2635e-06 - val_loss: 4.2910e-06\n",
      "Epoch 20/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.9169e-06 - val_loss: 4.1988e-06\n",
      "Epoch 21/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.1172e-06 - val_loss: 4.1943e-06\n",
      "Epoch 22/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7776e-06 - val_loss: 4.1735e-06\n",
      "Epoch 23/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2500e-06 - val_loss: 4.1477e-06\n",
      "Epoch 24/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.9609e-06 - val_loss: 4.1478e-06\n",
      "Epoch 25/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7638e-06 - val_loss: 4.1563e-06\n",
      "Epoch 26/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0395e-06 - val_loss: 4.0589e-06\n",
      "Epoch 27/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0678e-06 - val_loss: 4.0521e-06\n",
      "Epoch 28/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7091e-06 - val_loss: 4.0563e-06\n",
      "Epoch 29/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2771e-06 - val_loss: 4.0424e-06\n",
      "Epoch 30/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.3181e-06 - val_loss: 4.0516e-06\n",
      "Epoch 31/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0724e-06 - val_loss: 4.0869e-06\n",
      "Epoch 32/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.8765e-06 - val_loss: 4.0588e-06\n",
      "Epoch 33/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2906e-06 - val_loss: 3.9919e-06\n",
      "Epoch 34/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7642e-06 - val_loss: 3.9602e-06\n",
      "Epoch 35/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0760e-06 - val_loss: 3.9930e-06\n",
      "Epoch 36/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0882e-06 - val_loss: 3.9931e-06\n",
      "Epoch 37/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9597e-06 - val_loss: 4.0069e-06\n",
      "Epoch 38/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0964e-06 - val_loss: 3.9932e-06\n",
      "Epoch 39/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9613e-06 - val_loss: 3.9400e-06\n",
      "Epoch 40/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.7052e-06 - val_loss: 4.0485e-06\n",
      "Epoch 41/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.3484e-06 - val_loss: 4.0329e-06\n",
      "Epoch 42/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0074e-06 - val_loss: 4.0168e-06\n",
      "Epoch 43/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9370e-06 - val_loss: 3.9502e-06\n",
      "Epoch 44/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1306e-06 - val_loss: 4.0845e-06\n",
      "Epoch 45/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5453e-06 - val_loss: 3.9560e-06\n",
      "Epoch 46/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9106e-06 - val_loss: 3.9624e-06\n",
      "Epoch 47/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9190e-06 - val_loss: 3.9654e-06\n",
      "Epoch 48/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1174e-06 - val_loss: 3.9798e-06\n",
      "Epoch 49/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4600e-06 - val_loss: 3.9824e-06\n",
      "Epoch 1/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0405 - val_loss: 0.0127\n",
      "Epoch 2/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0124\n",
      "Epoch 3/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0124\n",
      "Epoch 4/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0126 - val_loss: 0.0126\n",
      "Epoch 5/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 6/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0124\n",
      "Epoch 7/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 8/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 9/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - val_loss: 0.0125\n",
      "Epoch 10/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 11/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0126 - val_loss: 0.0124\n",
      "Epoch 12/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0124\n",
      "Epoch 13/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0126 - val_loss: 0.0125\n",
      "Epoch 14/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 15/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 16/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 17/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0126 - val_loss: 0.0126\n",
      "Epoch 18/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0124\n",
      "Epoch 19/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - val_loss: 0.0125\n",
      "Epoch 20/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 21/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0124 - val_loss: 0.0126\n",
      "[[0.19415202 0.45286097 0.3196744 ]\n",
      " [0.30543361 0.34146584 0.29729138]\n",
      " [0.17257946 0.37526917 0.14115381]\n",
      " ...\n",
      " [0.67119842 0.41812982 0.28727392]\n",
      " [0.56129794 0.64709092 0.2510439 ]\n",
      " [0.825536   0.575869   0.49675327]]\n",
      "Epoch 1/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0866 - val_loss: 3.1076e-04\n",
      "Epoch 2/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6134e-04 - val_loss: 2.1936e-04\n",
      "Epoch 3/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9459e-04 - val_loss: 1.9683e-04\n",
      "Epoch 4/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9214e-04 - val_loss: 1.9399e-04\n",
      "Epoch 5/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7489e-04 - val_loss: 1.9412e-04\n",
      "Epoch 6/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8472e-04 - val_loss: 1.9289e-04\n",
      "Epoch 7/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7951e-04 - val_loss: 1.9258e-04\n",
      "Epoch 8/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8445e-04 - val_loss: 1.9364e-04\n",
      "Epoch 9/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8033e-04 - val_loss: 1.9273e-04\n",
      "Epoch 10/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8136e-04 - val_loss: 1.9263e-04\n",
      "Epoch 11/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7807e-04 - val_loss: 1.9227e-04\n",
      "Epoch 12/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7954e-04 - val_loss: 1.9264e-04\n",
      "Epoch 13/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7638e-04 - val_loss: 1.9221e-04\n",
      "Epoch 14/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8092e-04 - val_loss: 1.9261e-04\n",
      "Epoch 15/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7533e-04 - val_loss: 1.9143e-04\n",
      "Epoch 16/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6917e-04 - val_loss: 1.9311e-04\n",
      "Epoch 17/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8133e-04 - val_loss: 1.9385e-04\n",
      "Epoch 18/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8005e-04 - val_loss: 1.9134e-04\n",
      "Epoch 19/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7793e-04 - val_loss: 1.9202e-04\n",
      "Epoch 20/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7564e-04 - val_loss: 1.9121e-04\n",
      "Epoch 21/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7772e-04 - val_loss: 1.9191e-04\n",
      "Epoch 22/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8104e-04 - val_loss: 1.9171e-04\n",
      "Epoch 23/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6598e-04 - val_loss: 1.9213e-04\n",
      "Epoch 24/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7188e-04 - val_loss: 1.9162e-04\n",
      "Epoch 25/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8592e-04 - val_loss: 1.9199e-04\n",
      "Epoch 26/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7870e-04 - val_loss: 1.9257e-04\n",
      "Epoch 27/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8820e-04 - val_loss: 1.9090e-04\n",
      "Epoch 28/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7691e-04 - val_loss: 1.9099e-04\n",
      "Epoch 29/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7966e-04 - val_loss: 1.9066e-04\n",
      "Epoch 30/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7933e-04 - val_loss: 1.9076e-04\n",
      "Epoch 31/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7779e-04 - val_loss: 1.9023e-04\n",
      "Epoch 32/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7342e-04 - val_loss: 1.9147e-04\n",
      "Epoch 33/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7556e-04 - val_loss: 1.9059e-04\n",
      "Epoch 34/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7857e-04 - val_loss: 1.9090e-04\n",
      "Epoch 35/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8385e-04 - val_loss: 1.9043e-04\n",
      "Epoch 36/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8085e-04 - val_loss: 1.9065e-04\n",
      "Epoch 37/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7203e-04 - val_loss: 1.9187e-04\n",
      "Epoch 38/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7940e-04 - val_loss: 1.9055e-04\n",
      "Epoch 39/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7241e-04 - val_loss: 1.9088e-04\n",
      "Epoch 40/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7603e-04 - val_loss: 1.9094e-04\n",
      "Epoch 41/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7181e-04 - val_loss: 1.8992e-04\n",
      "Epoch 42/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7441e-04 - val_loss: 1.8965e-04\n",
      "Epoch 43/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8697e-04 - val_loss: 1.9081e-04\n",
      "Epoch 44/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7998e-04 - val_loss: 1.9007e-04\n",
      "Epoch 45/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7648e-04 - val_loss: 1.9095e-04\n",
      "Epoch 46/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8300e-04 - val_loss: 1.9053e-04\n",
      "Epoch 47/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8488e-04 - val_loss: 1.9031e-04\n",
      "Epoch 48/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7771e-04 - val_loss: 1.8991e-04\n",
      "Epoch 49/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6766e-04 - val_loss: 1.9004e-04\n",
      "Epoch 50/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7811e-04 - val_loss: 1.8908e-04\n",
      "Epoch 51/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6996e-04 - val_loss: 1.8932e-04\n",
      "Epoch 52/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8715e-04 - val_loss: 1.9127e-04\n",
      "Epoch 53/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7547e-04 - val_loss: 1.8892e-04\n",
      "Epoch 54/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8001e-04 - val_loss: 1.8983e-04\n",
      "Epoch 55/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7518e-04 - val_loss: 1.9006e-04\n",
      "Epoch 56/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7933e-04 - val_loss: 1.8955e-04\n",
      "Epoch 57/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6463e-04 - val_loss: 1.8889e-04\n",
      "Epoch 58/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7024e-04 - val_loss: 1.8931e-04\n",
      "Epoch 59/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7310e-04 - val_loss: 1.9017e-04\n",
      "Epoch 60/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7642e-04 - val_loss: 1.8861e-04\n",
      "Epoch 61/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8332e-04 - val_loss: 1.8938e-04\n",
      "Epoch 62/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7642e-04 - val_loss: 1.8986e-04\n",
      "Epoch 63/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7375e-04 - val_loss: 1.8943e-04\n",
      "Epoch 64/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7785e-04 - val_loss: 1.8892e-04\n",
      "Epoch 65/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7750e-04 - val_loss: 1.8927e-04\n",
      "Epoch 66/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7453e-04 - val_loss: 1.9078e-04\n",
      "Epoch 67/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8516e-04 - val_loss: 1.8896e-04\n",
      "Epoch 68/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6629e-04 - val_loss: 1.8903e-04\n",
      "Epoch 69/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7041e-04 - val_loss: 1.8847e-04\n",
      "Epoch 70/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8145e-04 - val_loss: 1.8893e-04\n",
      "Epoch 71/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7837e-04 - val_loss: 1.8896e-04\n",
      "Epoch 72/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6651e-04 - val_loss: 1.8861e-04\n",
      "Epoch 73/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6657e-04 - val_loss: 1.8782e-04\n",
      "Epoch 74/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7649e-04 - val_loss: 1.8815e-04\n",
      "Epoch 75/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7622e-04 - val_loss: 1.8790e-04\n",
      "Epoch 76/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7883e-04 - val_loss: 1.8957e-04\n",
      "Epoch 77/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6961e-04 - val_loss: 1.8757e-04\n",
      "Epoch 78/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7646e-04 - val_loss: 1.8735e-04\n",
      "Epoch 79/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7609e-04 - val_loss: 1.8743e-04\n",
      "Epoch 80/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7051e-04 - val_loss: 1.8735e-04\n",
      "Epoch 81/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6827e-04 - val_loss: 1.8722e-04\n",
      "Epoch 82/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7260e-04 - val_loss: 1.8680e-04\n",
      "Epoch 83/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7714e-04 - val_loss: 1.8690e-04\n",
      "Epoch 84/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7302e-04 - val_loss: 1.8678e-04\n",
      "Epoch 85/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6612e-04 - val_loss: 1.8780e-04\n",
      "Epoch 86/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6776e-04 - val_loss: 1.8665e-04\n",
      "Epoch 87/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7582e-04 - val_loss: 1.8631e-04\n",
      "Epoch 88/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6999e-04 - val_loss: 1.8629e-04\n",
      "Epoch 89/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8211e-04 - val_loss: 1.8669e-04\n",
      "Epoch 90/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6413e-04 - val_loss: 1.8649e-04\n",
      "Epoch 91/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7582e-04 - val_loss: 1.8619e-04\n",
      "Epoch 92/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7568e-04 - val_loss: 1.8590e-04\n",
      "Epoch 93/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7177e-04 - val_loss: 1.8558e-04\n",
      "Epoch 94/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6134e-04 - val_loss: 1.8579e-04\n",
      "Epoch 95/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6970e-04 - val_loss: 1.8535e-04\n",
      "Epoch 96/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7680e-04 - val_loss: 1.8486e-04\n",
      "Epoch 97/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6627e-04 - val_loss: 1.8620e-04\n",
      "Epoch 98/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7364e-04 - val_loss: 1.8528e-04\n",
      "Epoch 99/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7699e-04 - val_loss: 1.8536e-04\n",
      "Epoch 100/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6437e-04 - val_loss: 1.8566e-04\n",
      "Epoch 101/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7833e-04 - val_loss: 1.8553e-04\n",
      "Epoch 102/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6045e-04 - val_loss: 1.8505e-04\n",
      "Epoch 103/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5861e-04 - val_loss: 1.8487e-04\n",
      "Epoch 104/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6773e-04 - val_loss: 1.8441e-04\n",
      "Epoch 105/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6653e-04 - val_loss: 1.8398e-04\n",
      "Epoch 106/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6718e-04 - val_loss: 1.8526e-04\n",
      "Epoch 107/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7713e-04 - val_loss: 1.8476e-04\n",
      "Epoch 108/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6677e-04 - val_loss: 1.8427e-04\n",
      "Epoch 109/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6165e-04 - val_loss: 1.8430e-04\n",
      "Epoch 110/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5505e-04 - val_loss: 1.8503e-04\n",
      "Epoch 111/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6297e-04 - val_loss: 1.8336e-04\n",
      "Epoch 112/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6939e-04 - val_loss: 1.8432e-04\n",
      "Epoch 113/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7093e-04 - val_loss: 1.8337e-04\n",
      "Epoch 114/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7299e-04 - val_loss: 1.8347e-04\n",
      "Epoch 115/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7277e-04 - val_loss: 1.8336e-04\n",
      "Epoch 116/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6780e-04 - val_loss: 1.8325e-04\n",
      "Epoch 117/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5808e-04 - val_loss: 1.8272e-04\n",
      "Epoch 118/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6345e-04 - val_loss: 1.8319e-04\n",
      "Epoch 119/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7232e-04 - val_loss: 1.8410e-04\n",
      "Epoch 120/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6498e-04 - val_loss: 1.8289e-04\n",
      "Epoch 121/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6297e-04 - val_loss: 1.8306e-04\n",
      "Epoch 122/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6303e-04 - val_loss: 1.8307e-04\n",
      "Epoch 123/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5943e-04 - val_loss: 1.8244e-04\n",
      "Epoch 124/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6102e-04 - val_loss: 1.8245e-04\n",
      "Epoch 125/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6335e-04 - val_loss: 1.8352e-04\n",
      "Epoch 126/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5548e-04 - val_loss: 1.8211e-04\n",
      "Epoch 127/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6496e-04 - val_loss: 1.8200e-04\n",
      "Epoch 128/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6606e-04 - val_loss: 1.8266e-04\n",
      "Epoch 129/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6114e-04 - val_loss: 1.8265e-04\n",
      "Epoch 130/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6660e-04 - val_loss: 1.8238e-04\n",
      "Epoch 131/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6479e-04 - val_loss: 1.8164e-04\n",
      "Epoch 132/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6239e-04 - val_loss: 1.8215e-04\n",
      "Epoch 133/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6663e-04 - val_loss: 1.8168e-04\n",
      "Epoch 134/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6040e-04 - val_loss: 1.8234e-04\n",
      "Epoch 135/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5656e-04 - val_loss: 1.8148e-04\n",
      "Epoch 136/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6047e-04 - val_loss: 1.8174e-04\n",
      "Epoch 137/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5406e-04 - val_loss: 1.8164e-04\n",
      "Epoch 138/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6259e-04 - val_loss: 1.8119e-04\n",
      "Epoch 139/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5047e-04 - val_loss: 1.8231e-04\n",
      "Epoch 140/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6182e-04 - val_loss: 1.8129e-04\n",
      "Epoch 141/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5446e-04 - val_loss: 1.8158e-04\n",
      "Epoch 142/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6115e-04 - val_loss: 1.8107e-04\n",
      "Epoch 143/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6544e-04 - val_loss: 1.8157e-04\n",
      "Epoch 144/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6311e-04 - val_loss: 1.8092e-04\n",
      "Epoch 145/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5691e-04 - val_loss: 1.8112e-04\n",
      "Epoch 146/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5110e-04 - val_loss: 1.8246e-04\n",
      "Epoch 147/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5308e-04 - val_loss: 1.8080e-04\n",
      "Epoch 148/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6056e-04 - val_loss: 1.8152e-04\n",
      "Epoch 149/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7159e-04 - val_loss: 1.7989e-04\n",
      "Epoch 150/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5667e-04 - val_loss: 1.8015e-04\n",
      "Epoch 151/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5758e-04 - val_loss: 1.8002e-04\n",
      "Epoch 152/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6582e-04 - val_loss: 1.8071e-04\n",
      "Epoch 153/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6405e-04 - val_loss: 1.8087e-04\n",
      "Epoch 154/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6686e-04 - val_loss: 1.8270e-04\n",
      "Epoch 155/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5660e-04 - val_loss: 1.8141e-04\n",
      "Epoch 156/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5726e-04 - val_loss: 1.8025e-04\n",
      "Epoch 157/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5488e-04 - val_loss: 1.7995e-04\n",
      "Epoch 158/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5133e-04 - val_loss: 1.8183e-04\n",
      "Epoch 159/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6427e-04 - val_loss: 1.8037e-04\n",
      "Epoch 1/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0213 - val_loss: 0.0149\n",
      "Epoch 2/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - val_loss: 0.0156\n",
      "Epoch 3/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 4/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0143 - val_loss: 0.0148\n",
      "Epoch 5/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - val_loss: 0.0152\n",
      "Epoch 6/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0144 - val_loss: 0.0148\n",
      "Epoch 7/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0144 - val_loss: 0.0151\n",
      "Epoch 8/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0144 - val_loss: 0.0150\n",
      "Epoch 9/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - val_loss: 0.0149\n",
      "Epoch 10/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0141 - val_loss: 0.0149\n",
      "Epoch 11/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - val_loss: 0.0150\n",
      "Epoch 12/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0143 - val_loss: 0.0147\n",
      "Epoch 13/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0143 - val_loss: 0.0148\n",
      "Epoch 14/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - val_loss: 0.0148\n",
      "Epoch 15/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0143 - val_loss: 0.0148\n",
      "Epoch 16/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0141 - val_loss: 0.0148\n",
      "Epoch 17/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0141 - val_loss: 0.0148\n",
      "Epoch 18/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0140 - val_loss: 0.0153\n",
      "Epoch 19/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0144 - val_loss: 0.0148\n",
      "Epoch 20/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0143 - val_loss: 0.0151\n",
      "Epoch 21/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0141 - val_loss: 0.0150\n",
      "Epoch 22/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0145 - val_loss: 0.0153\n",
      "[[0.19415202 0.45286097 0.3196744  0.247095  ]\n",
      " [0.30543361 0.34146584 0.29729138 0.37259277]\n",
      " [0.17257946 0.37526917 0.14115381 0.31422743]\n",
      " ...\n",
      " [0.67119842 0.41812982 0.28727392 0.68362083]\n",
      " [0.56129794 0.64709092 0.2510439  0.7281221 ]\n",
      " [0.825536   0.575869   0.49675327 0.73472914]]\n",
      "Epoch 1/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0764 - val_loss: 8.8367e-04\n",
      "Epoch 2/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.3909e-04 - val_loss: 8.3142e-04\n",
      "Epoch 3/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.9762e-04 - val_loss: 7.8962e-04\n",
      "Epoch 4/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.7273e-04 - val_loss: 7.7824e-04\n",
      "Epoch 5/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5839e-04 - val_loss: 7.7328e-04\n",
      "Epoch 6/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5883e-04 - val_loss: 7.7194e-04\n",
      "Epoch 7/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5102e-04 - val_loss: 7.7127e-04\n",
      "Epoch 8/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.2651e-04 - val_loss: 7.7226e-04\n",
      "Epoch 9/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4237e-04 - val_loss: 7.7278e-04\n",
      "Epoch 10/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4238e-04 - val_loss: 7.6963e-04\n",
      "Epoch 11/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4263e-04 - val_loss: 7.6919e-04\n",
      "Epoch 12/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6357e-04 - val_loss: 7.6852e-04\n",
      "Epoch 13/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6841e-04 - val_loss: 7.6730e-04\n",
      "Epoch 14/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6257e-04 - val_loss: 7.6808e-04\n",
      "Epoch 15/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4475e-04 - val_loss: 7.6721e-04\n",
      "Epoch 16/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5630e-04 - val_loss: 7.6914e-04\n",
      "Epoch 17/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5830e-04 - val_loss: 7.7006e-04\n",
      "Epoch 18/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6438e-04 - val_loss: 7.6829e-04\n",
      "Epoch 19/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4324e-04 - val_loss: 7.6461e-04\n",
      "Epoch 20/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5298e-04 - val_loss: 7.6550e-04\n",
      "Epoch 21/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.3122e-04 - val_loss: 7.6848e-04\n",
      "Epoch 22/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5021e-04 - val_loss: 7.6759e-04\n",
      "Epoch 23/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4521e-04 - val_loss: 7.6887e-04\n",
      "Epoch 24/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4678e-04 - val_loss: 7.6760e-04\n",
      "Epoch 25/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6549e-04 - val_loss: 7.6818e-04\n",
      "Epoch 26/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3117e-04 - val_loss: 7.6393e-04\n",
      "Epoch 27/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5060e-04 - val_loss: 7.6378e-04\n",
      "Epoch 28/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6009e-04 - val_loss: 7.6616e-04\n",
      "Epoch 29/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6825e-04 - val_loss: 7.6539e-04\n",
      "Epoch 30/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5708e-04 - val_loss: 7.6415e-04\n",
      "Epoch 31/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4941e-04 - val_loss: 7.6718e-04\n",
      "Epoch 32/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6743e-04 - val_loss: 7.6428e-04\n",
      "Epoch 33/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6262e-04 - val_loss: 7.6420e-04\n",
      "Epoch 34/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3244e-04 - val_loss: 7.6709e-04\n",
      "Epoch 35/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4882e-04 - val_loss: 7.6882e-04\n",
      "Epoch 36/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5457e-04 - val_loss: 7.6482e-04\n",
      "Epoch 37/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5028e-04 - val_loss: 7.6375e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6562e-04 - val_loss: 7.6238e-04\n",
      "Epoch 39/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5544e-04 - val_loss: 7.6156e-04\n",
      "Epoch 40/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.3880e-04 - val_loss: 7.6336e-04\n",
      "Epoch 41/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5329e-04 - val_loss: 7.6405e-04\n",
      "Epoch 42/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6874e-04 - val_loss: 7.6163e-04\n",
      "Epoch 43/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3920e-04 - val_loss: 7.6462e-04\n",
      "Epoch 44/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4237e-04 - val_loss: 7.6415e-04\n",
      "Epoch 45/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6584e-04 - val_loss: 7.6212e-04\n",
      "Epoch 46/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5942e-04 - val_loss: 7.6343e-04\n",
      "Epoch 47/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5213e-04 - val_loss: 7.6216e-04\n",
      "Epoch 48/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4224e-04 - val_loss: 7.6040e-04\n",
      "Epoch 49/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5884e-04 - val_loss: 7.6384e-04\n",
      "Epoch 50/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.3004e-04 - val_loss: 7.6426e-04\n",
      "Epoch 51/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3514e-04 - val_loss: 7.6035e-04\n",
      "Epoch 52/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4778e-04 - val_loss: 7.6002e-04\n",
      "Epoch 53/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2558e-04 - val_loss: 7.6201e-04\n",
      "Epoch 54/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3050e-04 - val_loss: 7.6629e-04\n",
      "Epoch 55/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4058e-04 - val_loss: 7.6221e-04\n",
      "Epoch 56/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4844e-04 - val_loss: 7.6227e-04\n",
      "Epoch 57/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2223e-04 - val_loss: 7.6055e-04\n",
      "Epoch 58/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4044e-04 - val_loss: 7.6174e-04\n",
      "Epoch 59/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.3791e-04 - val_loss: 7.6142e-04\n",
      "Epoch 60/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4697e-04 - val_loss: 7.6246e-04\n",
      "Epoch 61/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.3913e-04 - val_loss: 7.6013e-04\n",
      "Epoch 62/2000\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2613e-04 - val_loss: 7.6099e-04\n"
     ]
    }
   ],
   "source": [
    "data_points = np.stack([ground[:,0], ground[:,1]])\n",
    "func_e_x2, func_x2_noise = data.trainANN('x2_given_x1', generate_models, data_points, [input_res], output_res, output_buffer)\n",
    "\n",
    "# C <- X1,X2\n",
    "generated_c = np.array([func_c_sampled(x) for x in ground[:,:2]])\n",
    "\n",
    "# X3 <- X1,X2,C\n",
    "data_points = np.stack([ground[:,0], ground[:,1], generated_c, ground[:,3]])\n",
    "func_e_x3, func_x3_noise = data.trainANN('x3_given_x1x2c', generate_models, data_points, [input_res,input_res,input_res], output_res, output_buffer)\n",
    "\n",
    "# S <- X1,X2,C,X3\n",
    "data_points = np.stack([ground[:,0], ground[:,1], generated_c, ground[:,3], ground[:,4]])\n",
    "func_e_s, func_s_noise  = data.trainANN('s_given_x1x2cx3', generate_models, data_points, [input_res,input_res,input_res,input_res], output_res, output_buffer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPbPtchE2OHv"
   },
   "source": [
    "# **Causal Jazz Simulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P5OsVPgc2mco",
    "outputId": "87427281-a3ff-4c17-d88b-068f501f6e4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In findNextFunctionAndApply, found function X2E at iteration 0\n",
      "Required input variables are: ['X10']\n",
      "['X10']\n",
      "[array([ 0.65553906, -1.39060544, -0.23496691,  1.30939573, -0.20399215,\n",
      "       -0.20691362, -0.60160275, -0.01782741,  0.33731722, -0.44379008,\n",
      "        0.13540547,  0.23653401, -0.72523348, -0.23267386,  0.75423203,\n",
      "        0.15914363,  1.0097213 , -0.25346209, -1.29088515, -0.46042593,\n",
      "        0.15145119,  0.92642759, -1.32151279,  0.72839253,  1.32189646,\n",
      "       -0.88630907,  2.35882009, -0.52842572,  0.00287391, -0.80968879,\n",
      "        2.2338624 ,  0.83077123, -1.24010352, -0.73118325,  1.1234118 ,\n",
      "       -1.03424634, -0.26975981,  0.19372783, -0.15615234,  0.94594288,\n",
      "        0.54066385,  1.42355206, -0.65406663,  0.06452185,  0.20546118,\n",
      "        2.08795238, -1.05655071,  1.14334421, -1.13844557,  1.02732752,\n",
      "        0.68140076, -1.21194884, -0.13007907, -0.37357335, -0.23521296,\n",
      "        2.20198315, -0.70994504,  1.17793784, -1.14905284, -0.05890571,\n",
      "        0.9493082 ,  0.21845018,  0.20726264,  0.69009761,  0.12963934,\n",
      "        1.22930908,  0.03932353,  1.77246914, -0.10288243, -0.29021475,\n",
      "       -2.11084851, -0.63210863,  0.74890601,  0.95983925, -0.68757451,\n",
      "        0.18209689,  0.43376817,  1.27105237,  0.33285811, -0.03481663,\n",
      "       -0.34920811, -0.04731387, -0.01689475,  1.31486509, -0.85598853,\n",
      "        0.12724693, -0.82759398, -1.81753528, -0.45588815, -0.92465664,\n",
      "       -0.40499687, -2.00682159,  0.45756521,  1.42398132,  1.14025756,\n",
      "        1.08538452, -0.54871143,  0.06077632, -0.65212145, -0.03149264])]\n",
      "[[ 0.65553906]\n",
      " [-1.39060544]\n",
      " [-0.23496691]\n",
      " [ 1.30939573]\n",
      " [-0.20399215]\n",
      " [-0.20691362]\n",
      " [-0.60160275]\n",
      " [-0.01782741]\n",
      " [ 0.33731722]\n",
      " [-0.44379008]\n",
      " [ 0.13540547]\n",
      " [ 0.23653401]\n",
      " [-0.72523348]\n",
      " [-0.23267386]\n",
      " [ 0.75423203]\n",
      " [ 0.15914363]\n",
      " [ 1.0097213 ]\n",
      " [-0.25346209]\n",
      " [-1.29088515]\n",
      " [-0.46042593]\n",
      " [ 0.15145119]\n",
      " [ 0.92642759]\n",
      " [-1.32151279]\n",
      " [ 0.72839253]\n",
      " [ 1.32189646]\n",
      " [-0.88630907]\n",
      " [ 2.35882009]\n",
      " [-0.52842572]\n",
      " [ 0.00287391]\n",
      " [-0.80968879]\n",
      " [ 2.2338624 ]\n",
      " [ 0.83077123]\n",
      " [-1.24010352]\n",
      " [-0.73118325]\n",
      " [ 1.1234118 ]\n",
      " [-1.03424634]\n",
      " [-0.26975981]\n",
      " [ 0.19372783]\n",
      " [-0.15615234]\n",
      " [ 0.94594288]\n",
      " [ 0.54066385]\n",
      " [ 1.42355206]\n",
      " [-0.65406663]\n",
      " [ 0.06452185]\n",
      " [ 0.20546118]\n",
      " [ 2.08795238]\n",
      " [-1.05655071]\n",
      " [ 1.14334421]\n",
      " [-1.13844557]\n",
      " [ 1.02732752]\n",
      " [ 0.68140076]\n",
      " [-1.21194884]\n",
      " [-0.13007907]\n",
      " [-0.37357335]\n",
      " [-0.23521296]\n",
      " [ 2.20198315]\n",
      " [-0.70994504]\n",
      " [ 1.17793784]\n",
      " [-1.14905284]\n",
      " [-0.05890571]\n",
      " [ 0.9493082 ]\n",
      " [ 0.21845018]\n",
      " [ 0.20726264]\n",
      " [ 0.69009761]\n",
      " [ 0.12963934]\n",
      " [ 1.22930908]\n",
      " [ 0.03932353]\n",
      " [ 1.77246914]\n",
      " [-0.10288243]\n",
      " [-0.29021475]\n",
      " [-2.11084851]\n",
      " [-0.63210863]\n",
      " [ 0.74890601]\n",
      " [ 0.95983925]\n",
      " [-0.68757451]\n",
      " [ 0.18209689]\n",
      " [ 0.43376817]\n",
      " [ 1.27105237]\n",
      " [ 0.33285811]\n",
      " [-0.03481663]\n",
      " [-0.34920811]\n",
      " [-0.04731387]\n",
      " [-0.01689475]\n",
      " [ 1.31486509]\n",
      " [-0.85598853]\n",
      " [ 0.12724693]\n",
      " [-0.82759398]\n",
      " [-1.81753528]\n",
      " [-0.45588815]\n",
      " [-0.92465664]\n",
      " [-0.40499687]\n",
      " [-2.00682159]\n",
      " [ 0.45756521]\n",
      " [ 1.42398132]\n",
      " [ 1.14025756]\n",
      " [ 1.08538452]\n",
      " [-0.54871143]\n",
      " [ 0.06077632]\n",
      " [-0.65212145]\n",
      " [-0.03149264]]\n",
      "[[ 0.65553906]\n",
      " [-1.39060544]\n",
      " [-0.23496691]\n",
      " [ 1.30939573]\n",
      " [-0.20399215]\n",
      " [-0.20691362]\n",
      " [-0.60160275]\n",
      " [-0.01782741]\n",
      " [ 0.33731722]\n",
      " [-0.44379008]\n",
      " [ 0.13540547]\n",
      " [ 0.23653401]\n",
      " [-0.72523348]\n",
      " [-0.23267386]\n",
      " [ 0.75423203]\n",
      " [ 0.15914363]\n",
      " [ 1.0097213 ]\n",
      " [-0.25346209]\n",
      " [-1.29088515]\n",
      " [-0.46042593]\n",
      " [ 0.15145119]\n",
      " [ 0.92642759]\n",
      " [-1.32151279]\n",
      " [ 0.72839253]\n",
      " [ 1.32189646]\n",
      " [-0.88630907]\n",
      " [ 2.35882009]\n",
      " [-0.52842572]\n",
      " [ 0.00287391]\n",
      " [-0.80968879]\n",
      " [ 2.2338624 ]\n",
      " [ 0.83077123]\n",
      " [-1.24010352]\n",
      " [-0.73118325]\n",
      " [ 1.1234118 ]\n",
      " [-1.03424634]\n",
      " [-0.26975981]\n",
      " [ 0.19372783]\n",
      " [-0.15615234]\n",
      " [ 0.94594288]\n",
      " [ 0.54066385]\n",
      " [ 1.42355206]\n",
      " [-0.65406663]\n",
      " [ 0.06452185]\n",
      " [ 0.20546118]\n",
      " [ 2.08795238]\n",
      " [-1.05655071]\n",
      " [ 1.14334421]\n",
      " [-1.13844557]\n",
      " [ 1.02732752]\n",
      " [ 0.68140076]\n",
      " [-1.21194884]\n",
      " [-0.13007907]\n",
      " [-0.37357335]\n",
      " [-0.23521296]\n",
      " [ 2.20198315]\n",
      " [-0.70994504]\n",
      " [ 1.17793784]\n",
      " [-1.14905284]\n",
      " [-0.05890571]\n",
      " [ 0.9493082 ]\n",
      " [ 0.21845018]\n",
      " [ 0.20726264]\n",
      " [ 0.69009761]\n",
      " [ 0.12963934]\n",
      " [ 1.22930908]\n",
      " [ 0.03932353]\n",
      " [ 1.77246914]\n",
      " [-0.10288243]\n",
      " [-0.29021475]\n",
      " [-2.11084851]\n",
      " [-0.63210863]\n",
      " [ 0.74890601]\n",
      " [ 0.95983925]\n",
      " [-0.68757451]\n",
      " [ 0.18209689]\n",
      " [ 0.43376817]\n",
      " [ 1.27105237]\n",
      " [ 0.33285811]\n",
      " [-0.03481663]\n",
      " [-0.34920811]\n",
      " [-0.04731387]\n",
      " [-0.01689475]\n",
      " [ 1.31486509]\n",
      " [-0.85598853]\n",
      " [ 0.12724693]\n",
      " [-0.82759398]\n",
      " [-1.81753528]\n",
      " [-0.45588815]\n",
      " [-0.92465664]\n",
      " [-0.40499687]\n",
      " [-2.00682159]\n",
      " [ 0.45756521]\n",
      " [ 1.42398132]\n",
      " [ 1.14025756]\n",
      " [ 1.08538452]\n",
      " [-0.54871143]\n",
      " [ 0.06077632]\n",
      " [-0.65212145]\n",
      " [-0.03149264]]\n",
      "Current Nodes: ['X10', 'X2E0']\n",
      "In findNextFunctionAndApply, found function X2N at iteration 0\n",
      "Required input variables are: ['X10']\n",
      "['X10']\n",
      "[array([ 0.65553906, -1.39060544, -0.23496691,  1.30939573, -0.20399215,\n",
      "       -0.20691362, -0.60160275, -0.01782741,  0.33731722, -0.44379008,\n",
      "        0.13540547,  0.23653401, -0.72523348, -0.23267386,  0.75423203,\n",
      "        0.15914363,  1.0097213 , -0.25346209, -1.29088515, -0.46042593,\n",
      "        0.15145119,  0.92642759, -1.32151279,  0.72839253,  1.32189646,\n",
      "       -0.88630907,  2.35882009, -0.52842572,  0.00287391, -0.80968879,\n",
      "        2.2338624 ,  0.83077123, -1.24010352, -0.73118325,  1.1234118 ,\n",
      "       -1.03424634, -0.26975981,  0.19372783, -0.15615234,  0.94594288,\n",
      "        0.54066385,  1.42355206, -0.65406663,  0.06452185,  0.20546118,\n",
      "        2.08795238, -1.05655071,  1.14334421, -1.13844557,  1.02732752,\n",
      "        0.68140076, -1.21194884, -0.13007907, -0.37357335, -0.23521296,\n",
      "        2.20198315, -0.70994504,  1.17793784, -1.14905284, -0.05890571,\n",
      "        0.9493082 ,  0.21845018,  0.20726264,  0.69009761,  0.12963934,\n",
      "        1.22930908,  0.03932353,  1.77246914, -0.10288243, -0.29021475,\n",
      "       -2.11084851, -0.63210863,  0.74890601,  0.95983925, -0.68757451,\n",
      "        0.18209689,  0.43376817,  1.27105237,  0.33285811, -0.03481663,\n",
      "       -0.34920811, -0.04731387, -0.01689475,  1.31486509, -0.85598853,\n",
      "        0.12724693, -0.82759398, -1.81753528, -0.45588815, -0.92465664,\n",
      "       -0.40499687, -2.00682159,  0.45756521,  1.42398132,  1.14025756,\n",
      "        1.08538452, -0.54871143,  0.06077632, -0.65212145, -0.03149264])]\n",
      "[[ 0.65553906]\n",
      " [-1.39060544]\n",
      " [-0.23496691]\n",
      " [ 1.30939573]\n",
      " [-0.20399215]\n",
      " [-0.20691362]\n",
      " [-0.60160275]\n",
      " [-0.01782741]\n",
      " [ 0.33731722]\n",
      " [-0.44379008]\n",
      " [ 0.13540547]\n",
      " [ 0.23653401]\n",
      " [-0.72523348]\n",
      " [-0.23267386]\n",
      " [ 0.75423203]\n",
      " [ 0.15914363]\n",
      " [ 1.0097213 ]\n",
      " [-0.25346209]\n",
      " [-1.29088515]\n",
      " [-0.46042593]\n",
      " [ 0.15145119]\n",
      " [ 0.92642759]\n",
      " [-1.32151279]\n",
      " [ 0.72839253]\n",
      " [ 1.32189646]\n",
      " [-0.88630907]\n",
      " [ 2.35882009]\n",
      " [-0.52842572]\n",
      " [ 0.00287391]\n",
      " [-0.80968879]\n",
      " [ 2.2338624 ]\n",
      " [ 0.83077123]\n",
      " [-1.24010352]\n",
      " [-0.73118325]\n",
      " [ 1.1234118 ]\n",
      " [-1.03424634]\n",
      " [-0.26975981]\n",
      " [ 0.19372783]\n",
      " [-0.15615234]\n",
      " [ 0.94594288]\n",
      " [ 0.54066385]\n",
      " [ 1.42355206]\n",
      " [-0.65406663]\n",
      " [ 0.06452185]\n",
      " [ 0.20546118]\n",
      " [ 2.08795238]\n",
      " [-1.05655071]\n",
      " [ 1.14334421]\n",
      " [-1.13844557]\n",
      " [ 1.02732752]\n",
      " [ 0.68140076]\n",
      " [-1.21194884]\n",
      " [-0.13007907]\n",
      " [-0.37357335]\n",
      " [-0.23521296]\n",
      " [ 2.20198315]\n",
      " [-0.70994504]\n",
      " [ 1.17793784]\n",
      " [-1.14905284]\n",
      " [-0.05890571]\n",
      " [ 0.9493082 ]\n",
      " [ 0.21845018]\n",
      " [ 0.20726264]\n",
      " [ 0.69009761]\n",
      " [ 0.12963934]\n",
      " [ 1.22930908]\n",
      " [ 0.03932353]\n",
      " [ 1.77246914]\n",
      " [-0.10288243]\n",
      " [-0.29021475]\n",
      " [-2.11084851]\n",
      " [-0.63210863]\n",
      " [ 0.74890601]\n",
      " [ 0.95983925]\n",
      " [-0.68757451]\n",
      " [ 0.18209689]\n",
      " [ 0.43376817]\n",
      " [ 1.27105237]\n",
      " [ 0.33285811]\n",
      " [-0.03481663]\n",
      " [-0.34920811]\n",
      " [-0.04731387]\n",
      " [-0.01689475]\n",
      " [ 1.31486509]\n",
      " [-0.85598853]\n",
      " [ 0.12724693]\n",
      " [-0.82759398]\n",
      " [-1.81753528]\n",
      " [-0.45588815]\n",
      " [-0.92465664]\n",
      " [-0.40499687]\n",
      " [-2.00682159]\n",
      " [ 0.45756521]\n",
      " [ 1.42398132]\n",
      " [ 1.14025756]\n",
      " [ 1.08538452]\n",
      " [-0.54871143]\n",
      " [ 0.06077632]\n",
      " [-0.65212145]\n",
      " [-0.03149264]]\n",
      "[[ 0.65553906]\n",
      " [-1.39060544]\n",
      " [-0.23496691]\n",
      " [ 1.30939573]\n",
      " [-0.20399215]\n",
      " [-0.20691362]\n",
      " [-0.60160275]\n",
      " [-0.01782741]\n",
      " [ 0.33731722]\n",
      " [-0.44379008]\n",
      " [ 0.13540547]\n",
      " [ 0.23653401]\n",
      " [-0.72523348]\n",
      " [-0.23267386]\n",
      " [ 0.75423203]\n",
      " [ 0.15914363]\n",
      " [ 1.0097213 ]\n",
      " [-0.25346209]\n",
      " [-1.29088515]\n",
      " [-0.46042593]\n",
      " [ 0.15145119]\n",
      " [ 0.92642759]\n",
      " [-1.32151279]\n",
      " [ 0.72839253]\n",
      " [ 1.32189646]\n",
      " [-0.88630907]\n",
      " [ 2.35882009]\n",
      " [-0.52842572]\n",
      " [ 0.00287391]\n",
      " [-0.80968879]\n",
      " [ 2.2338624 ]\n",
      " [ 0.83077123]\n",
      " [-1.24010352]\n",
      " [-0.73118325]\n",
      " [ 1.1234118 ]\n",
      " [-1.03424634]\n",
      " [-0.26975981]\n",
      " [ 0.19372783]\n",
      " [-0.15615234]\n",
      " [ 0.94594288]\n",
      " [ 0.54066385]\n",
      " [ 1.42355206]\n",
      " [-0.65406663]\n",
      " [ 0.06452185]\n",
      " [ 0.20546118]\n",
      " [ 2.08795238]\n",
      " [-1.05655071]\n",
      " [ 1.14334421]\n",
      " [-1.13844557]\n",
      " [ 1.02732752]\n",
      " [ 0.68140076]\n",
      " [-1.21194884]\n",
      " [-0.13007907]\n",
      " [-0.37357335]\n",
      " [-0.23521296]\n",
      " [ 2.20198315]\n",
      " [-0.70994504]\n",
      " [ 1.17793784]\n",
      " [-1.14905284]\n",
      " [-0.05890571]\n",
      " [ 0.9493082 ]\n",
      " [ 0.21845018]\n",
      " [ 0.20726264]\n",
      " [ 0.69009761]\n",
      " [ 0.12963934]\n",
      " [ 1.22930908]\n",
      " [ 0.03932353]\n",
      " [ 1.77246914]\n",
      " [-0.10288243]\n",
      " [-0.29021475]\n",
      " [-2.11084851]\n",
      " [-0.63210863]\n",
      " [ 0.74890601]\n",
      " [ 0.95983925]\n",
      " [-0.68757451]\n",
      " [ 0.18209689]\n",
      " [ 0.43376817]\n",
      " [ 1.27105237]\n",
      " [ 0.33285811]\n",
      " [-0.03481663]\n",
      " [-0.34920811]\n",
      " [-0.04731387]\n",
      " [-0.01689475]\n",
      " [ 1.31486509]\n",
      " [-0.85598853]\n",
      " [ 0.12724693]\n",
      " [-0.82759398]\n",
      " [-1.81753528]\n",
      " [-0.45588815]\n",
      " [-0.92465664]\n",
      " [-0.40499687]\n",
      " [-2.00682159]\n",
      " [ 0.45756521]\n",
      " [ 1.42398132]\n",
      " [ 1.14025756]\n",
      " [ 1.08538452]\n",
      " [-0.54871143]\n",
      " [ 0.06077632]\n",
      " [-0.65212145]\n",
      " [-0.03149264]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Nodes: ['X10', 'X2E0', 'X2N0']\n",
      "In findNextFunctionAndApply, found function X2 at iteration 0\n",
      "Required input variables are: ['X2E0', 'X2N0']\n",
      "['X2E0', 'X2N0']\n",
      "[array([[0.5474166 ],\n",
      "       [0.3278647 ],\n",
      "       [0.32806396],\n",
      "       [0.69732255],\n",
      "       [0.33421707],\n",
      "       [0.33360332],\n",
      "       [0.29055083],\n",
      "       [0.38682574],\n",
      "       [0.48876083],\n",
      "       [0.29801035],\n",
      "       [0.43876362],\n",
      "       [0.47087562],\n",
      "       [0.29160035],\n",
      "       [0.32854438],\n",
      "       [0.5660919 ],\n",
      "       [0.44664955],\n",
      "       [0.61466205],\n",
      "       [0.32425284],\n",
      "       [0.32042128],\n",
      "       [0.29669452],\n",
      "       [0.44410628],\n",
      "       [0.59869134],\n",
      "       [0.32254732],\n",
      "       [0.5612024 ],\n",
      "       [0.7019439 ],\n",
      "       [0.2953673 ],\n",
      "       [1.0855241 ],\n",
      "       [0.29256272],\n",
      "       [0.3942957 ],\n",
      "       [0.29319733],\n",
      "       [1.0391747 ],\n",
      "       [0.580573  ],\n",
      "       [0.31689614],\n",
      "       [0.29168344],\n",
      "       [0.6376205 ],\n",
      "       [0.3032331 ],\n",
      "       [0.3213237 ],\n",
      "       [0.45825654],\n",
      "       [0.34571505],\n",
      "       [0.60243326],\n",
      "       [0.5259633 ],\n",
      "       [0.7395243 ],\n",
      "       [0.29062474],\n",
      "       [0.41490978],\n",
      "       [0.46201134],\n",
      "       [0.985215  ],\n",
      "       [0.30467004],\n",
      "       [0.64208955],\n",
      "       [0.31008965],\n",
      "       [0.6180379 ],\n",
      "       [0.5523103 ],\n",
      "       [0.3149566 ],\n",
      "       [0.35253096],\n",
      "       [0.3051703 ],\n",
      "       [0.3280124 ],\n",
      "       [1.0273854 ],\n",
      "       [0.29138684],\n",
      "       [0.6504528 ],\n",
      "       [0.31079197],\n",
      "       [0.3727376 ],\n",
      "       [0.6030784 ],\n",
      "       [0.46605188],\n",
      "       [0.46258777],\n",
      "       [0.553956  ],\n",
      "       [0.43681014],\n",
      "       [0.6677158 ],\n",
      "       [0.40654695],\n",
      "       [0.86854446],\n",
      "       [0.3598618 ],\n",
      "       [0.31796432],\n",
      "       [0.39366442],\n",
      "       [0.2903924 ],\n",
      "       [0.5650841 ],\n",
      "       [0.6050977 ],\n",
      "       [0.29107434],\n",
      "       [0.45431542],\n",
      "       [0.506152  ],\n",
      "       [0.68314755],\n",
      "       [0.48801726],\n",
      "       [0.38082844],\n",
      "       [0.30900216],\n",
      "       [0.37651646],\n",
      "       [0.38717145],\n",
      "       [0.69934446],\n",
      "       [0.2945034 ],\n",
      "       [0.4359944 ],\n",
      "       [0.29369384],\n",
      "       [0.3655315 ],\n",
      "       [0.29705352],\n",
      "       [0.29656583],\n",
      "       [0.30153304],\n",
      "       [0.3836124 ],\n",
      "       [0.510562  ],\n",
      "       [0.7396829 ],\n",
      "       [0.64139754],\n",
      "       [0.62916976],\n",
      "       [0.29168504],\n",
      "       [0.41366374],\n",
      "       [0.2905994 ],\n",
      "       [0.3819884 ]], dtype=float32), [[0.009841563516386341]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m tedag\u001b[38;5;241m.\u001b[39maddIntervention([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX1\u001b[39m\u001b[38;5;124m'\u001b[39m], [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, size\u001b[38;5;241m=\u001b[39mnumber_agents)], \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Forward calculate the distributions\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m tedag\u001b[38;5;241m.\u001b[39mfindNextFunctionAndApply(\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\causaljazz\\inference.py:105\u001b[0m, in \u001b[0;36mTEDAG.findNextFunctionAndApply\u001b[1;34m(self, iteration)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(func_arg_node_keys)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_nodes[a]\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m func_arg_node_keys])\n\u001b[1;32m--> 105\u001b[0m input_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_nodes[a]\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m func_arg_node_keys])\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_array\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m    107\u001b[0m new_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTEDAG_NODE(func\u001b[38;5;241m.\u001b[39mresult, func\u001b[38;5;241m.\u001b[39mfunc(input_array\u001b[38;5;241m.\u001b[39mT), iteration)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "def func_sum(y):\n",
    "  out = np.reshape(np.sum(y, axis=-1), (np.array(y).shape[0],1))\n",
    "  print(out.shape)\n",
    "  return out\n",
    "\n",
    "# Define the variable names for each function in TEDAG\n",
    "tedag_func_x2_e = TEDAG_FUNCTION(['X1'], 'X2E', 0, func_e_x2)\n",
    "tedag_func_x2_noise = TEDAG_FUNCTION(['X1'], 'X2N', 0, func_x2_noise)\n",
    "tedag_func_x2 = TEDAG_FUNCTION(['X2E', 'X2N'], 'X2', 0, func_sum)\n",
    "tedag_func_lc_e = TEDAG_FUNCTION(['X1', 'X2'], 'LCE', 0, func_c_exp)\n",
    "tedag_func_lc_noise = TEDAG_FUNCTION(['X1', 'X2'], 'LCN', 0, func_c_noise)\n",
    "tedag_func_lc = TEDAG_FUNCTION(['LCE', 'LCN'], 'LC', 0, func_sum)\n",
    "tedag_func_x3_e = TEDAG_FUNCTION(['X1', 'X2', 'LC'], 'X3E', 0, func_e_x3)\n",
    "tedag_func_x3_noise = TEDAG_FUNCTION(['X1', 'X2', 'LC'], 'X3N', 0, func_x3_noise)\n",
    "tedag_func_x3 = TEDAG_FUNCTION(['X3E', 'X3N'], 'X3', 0, func_sum)\n",
    "tedag_func_s_e  = TEDAG_FUNCTION(['X1', 'X2', 'LC', 'X3'], 'SE', 0, func_e_s)\n",
    "tedag_func_s_noise  = TEDAG_FUNCTION(['X1', 'X2', 'LC', 'X3'], 'SN', 0, func_s_noise)\n",
    "tedag_func_s = TEDAG_FUNCTION(['SE', 'SN'], 'S', 0, func_sum)\n",
    "\n",
    "number_agents = 100\n",
    "\n",
    "# Initialise the TEDAG\n",
    "tedag = TEDAG(1, [tedag_func_x2_e,tedag_func_x2_noise,tedag_func_lc_e,tedag_func_lc_noise,tedag_func_x2,tedag_func_lc,tedag_func_x3_e,tedag_func_x3_noise,tedag_func_x3,tedag_func_s_e,tedag_func_s_noise,tedag_func_s], observables=['X1', 'X2', 'LC', 'X3', 'S'], verbose=True)\n",
    "\n",
    "# Add a single intervention to set X1\n",
    "tedag.addIntervention(['X1'], [np.random.normal(0.0, 1.0, size=number_agents)], 0)\n",
    "\n",
    "# Forward calculate the distributions\n",
    "while tedag.findNextFunctionAndApply(0):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQhdACA39M8d"
   },
   "source": [
    "Let's plot the points and compare to the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "llntMRJg9SDk",
    "outputId": "e4aa6fb4-3c83-48e2-996f-4f4a70c72135"
   },
   "outputs": [],
   "source": [
    "space = [0.0, 1.0, 0.0, 1.0]\n",
    "var_names = ['X1', 'S']\n",
    "\n",
    "state = tedag.getSubState(var_names, 0)\n",
    "\n",
    "fig = plt.figure(1, dpi=100)\n",
    "plt.xlim([space[0],space[1]])\n",
    "plt.xlabel(var_names[0])\n",
    "plt.ylabel(var_names[1])\n",
    "plt.ylim([space[2],space[3]])\n",
    "plt.scatter(ground[:100,0],ground[:100,4],s=1.0,color='#FF00FF')\n",
    "plt.scatter(state[0,:100],state[0,:100],s=0.2)\n",
    "plt.show(block=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
